<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ollama on AI</title><link>https://ai.mzfqy.site/tags/ollama/</link><description>Recent content in Ollama on AI</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sun, 31 Mar 2024 19:06:02 +0800</lastBuildDate><atom:link href="https://ai.mzfqy.site/tags/ollama/rss.xml" rel="self" type="application/rss+xml"/><item><title>搭建本地大模型和知识库最简单的方法</title><link>https://ai.mzfqy.site/post/5/</link><pubDate>Sun, 31 Mar 2024 19:06:02 +0800</pubDate><guid>https://ai.mzfqy.site/post/5/</guid><description>01、本地大模型越来越简单 经过了一年多时间的迭代，大模型种类繁多，使用也越来越简单了。 在本地跑大模型，个人认为目前最好的软件肯定是Ollam</description></item></channel></rss>