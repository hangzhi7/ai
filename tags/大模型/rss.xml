<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>大模型 on AI</title><link>https://ai.mzfqy.site/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/</link><description>Recent content in 大模型 on AI</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sun, 31 Mar 2024 19:06:02 +0800</lastBuildDate><atom:link href="https://ai.mzfqy.site/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/rss.xml" rel="self" type="application/rss+xml"/><item><title>搭建本地大模型和知识库最简单的方法</title><link>https://ai.mzfqy.site/post/5/</link><pubDate>Sun, 31 Mar 2024 19:06:02 +0800</pubDate><guid>https://ai.mzfqy.site/post/5/</guid><description>01、本地大模型越来越简单 经过了一年多时间的迭代，大模型种类繁多，使用也越来越简单了。 在本地跑大模型，个人认为目前最好的软件肯定是Ollam</description></item><item><title>GPT大模型不再遥不可及：本地化部署让每个人都能拥有</title><link>https://ai.mzfqy.site/post/3/</link><pubDate>Sun, 12 Nov 2023 20:06:02 +0800</pubDate><guid>https://ai.mzfqy.site/post/3/</guid><description>01、本地化部署是GPT发展的一个趋势 我们提到大模型就想到这个东西不是我们普通人可以拥有的，因为太耗费服务器资源，注定了可以提供大模型服务的</description></item></channel></rss>